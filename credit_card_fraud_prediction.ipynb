{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "credit-card-fraud-prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPia1SX5BJXpRRAN+xE7o6r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/polo-music/credit-card-fraud-detection/blob/main/credit_card_fraud_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Idea & project\n",
        "The idea of this project is, by fitting different binary classification algorithms from the sklearn library, try to find one that can predict with a solid amount of security if a credit card transaction is fraudulent or not.\n",
        "\n",
        "After doing this project I found that work with this amount of unbalanced data is difficult and challenging. I've ended up cleaning the dataset to a less big and more reliable version."
      ],
      "metadata": {
        "id": "N1p1aUTtD173"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libreries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as ex\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# The dataset is too large to load into GitHub (150MB), I uploaded it into the Disk space of Google Colab\n",
        "df = pd.read_csv('/content/creditcard.csv')\n",
        "\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIlpLOtQEH4l",
        "outputId": "f508350c-8f88-4180-b281-8edd6c6e0d89"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Time            V1            V2            V3            V4  \\\n",
            "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
            "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
            "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
            "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
            "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
            "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
            "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
            "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
            "\n",
            "                 V5            V6            V7            V8            V9  \\\n",
            "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
            "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
            "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
            "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
            "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
            "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
            "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
            "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
            "\n",
            "       ...           V21           V22           V23           V24  \\\n",
            "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
            "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
            "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
            "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
            "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
            "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
            "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
            "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
            "\n",
            "                V25           V26           V27           V28         Amount  \\\n",
            "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
            "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
            "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
            "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
            "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
            "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
            "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
            "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
            "\n",
            "               Class  \n",
            "count  284807.000000  \n",
            "mean        0.001727  \n",
            "std         0.041527  \n",
            "min         0.000000  \n",
            "25%         0.000000  \n",
            "50%         0.000000  \n",
            "75%         0.000000  \n",
            "max         1.000000  \n",
            "\n",
            "[8 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay. The dataset is loaded. There is a lot of featured values \n",
        "(from V1 to V28) which contain different numbers. The dataset \n",
        "documentation tells us that there are only numerical values informing of the PCA transformation but due to confidentiality issues they cannot provide the original feature and more background. This should not be a problem since its the machine learning algorithm that will take care of \"understening\" this values. The only problem is that us, as humans, could not know if its getting the job well done or not. The two columns we're interested in are the \"amount\" coulumn, the \"time\" coulmn and the \"class\" column (binary being 1 fraud an 0 non fraud)."
      ],
      "metadata": {
        "id": "0UOUyIgbQY-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Since the dataset is too large and there are too variables involved I think it will not be useful to try to visualize\n",
        "# some sort of grah. Lets get to the real deal.\n",
        "# Now lets split the data to try to test some algorithms\n",
        "x = df.drop(labels = ['Class'], axis = 1)\n",
        "y = df['Class']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 7)"
      ],
      "metadata": {
        "id": "lF5QNVlhRV_R"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree Algorithm\n",
        "\n",
        "The decision tree is the simplest and most popular classification algorithm. For building the model the decision tree algorithm considers all the provided features of the data and comes up with the important features.\n",
        "\n",
        "Because of this advantage, the decision tree algorithms also used in identifying the importance of the feature metrics. Which used in handpicking the features. \n",
        "\n",
        "Once the important features identified then the model trains with the training data to come up with a set of rules. These rules used in predicting future cases or for the test dataset. \n",
        "\n",
        "We will try to divide the model from class and test the output."
      ],
      "metadata": {
        "id": "kNwERPYlS0BG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare instance of DTC and train the model\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mnl7cqhbS838",
        "outputId": "da2c05a2-dff0-4a59-ae58-b0f5ed1028fa"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We insert another code cell to avoid reloading the model\n",
        "y_predict = decision_tree.predict(x_test)\n",
        "acc = decision_tree.score(x_test, y_test)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRMJv9aaZ9Ma",
        "outputId": "d3a1e2f4-a204-414b-82b4-fa8b278c01ff"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9991924440855307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wow! The accuracy of our model is 99.9% but does this mean that it is a good model?\n",
        "Sometimes accuracy is not the real metric to help us say if a model is good or bad, and in this case it sure isn't. Let's dive in what really accuracy is:\n",
        ">We know that accuracy is the number of true results among all the cases. \n",
        "\n",
        "Keeping in mind our dataset, we can clarely see why this accuracy is so high. We stated at the beginning of the project that our dataset had class 1 and class 0 transactions, but the relationship to one another was an extremily low 0.17%. So, lets imagine that the model (for some reason) always says that the transaction is valid. Having this relationship even if some transactions are fraud, the difference is so big that it always will be a super high accuracy. That's why this particular metric does not work in this case\n",
        "\n",
        "> Before starting any coding or designing any algorithm, I always recommend to pause a minute and invest the time in DEEPLY understend what kind of dataset are we working with and what type of question we want to ask. With this in mind, the above assumption is done almost immidiately.\n",
        "\n",
        "After looking at this particular case, we can affirm that accuracy is a good metric when we have a well balanced bunch of data (not this case)."
      ],
      "metadata": {
        "id": "y3CNEOFGmCWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For deep diving in the real metrics of the algorithm, lets print some classification report\n",
        "# This should give us something more to work with and give us a deeper understanding of the model itself\n",
        "print(classification_report(y_test, y_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFQlNSYmmCpT",
        "outputId": "e2ae90b1-c33c-40a3-ec3c-8ccd80940c74"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56862\n",
            "           1       0.76      0.79      0.77       100\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.88      0.89      0.89     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this, we will use the method **classification_report** from the sklearn library.\n",
        "\n",
        "This method give us some more classification reports to take into account when validating models. It's time to deep dive into some of thses :)\n",
        "\n",
        "---\n",
        "\n",
        "First of all, we have to take a step back and understend what valeues we're working with when we do a ML prediction (or some prediction of any kind). The 'values' we have are these:\n",
        "\n",
        "|  | Actual data | Actual data |  |\n",
        "| --- | --- | --- | --- |\n",
        "|  |Positive (actual data) | Negative (actual data) |\n",
        "| Positive (predicted data) | TP | FP |\n",
        "| Negative (predicted data)| FN | TN |\n",
        "\n",
        "Being the values of the matrix the following:\n",
        "\n",
        "\n",
        "*   TP: True Positive\n",
        "*   FP: False Positive\n",
        "*   FN: False Negative\n",
        "*   TN: True Negative\n",
        "\n",
        "This is good to keep in mind because we can extract some formulas and some concepts from it to try to understand the real performance of the actual model we're working with.\n",
        "\n",
        "## Accuracy\n",
        "As we stated before, the accuracy is the amount of \"trues\" the model got from the total amount of data.\n",
        "> Accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
        "\n",
        "In this case, when we have a heavely unbalanced data, this is not the best classification information we can extract.\n",
        "\n",
        "## Precision\n",
        "When we talk about precision we mean: \"what proportion of predicted positive is actually positive?\"\n",
        "> Precision = TP / (TP + FP)\n",
        "\n",
        "The precision metric works well when we want to be sure of what we're doing (i.e. if we're talking about administer some medicine to a patient).\n",
        "\n",
        "## Recall\n",
        "The recall measure a different point of view from the model: \"what proportion of actual positive is correct in the classification?\"\n",
        "> Recall = TP / (TP + FN)\n",
        "\n",
        "The recall metric is useful when (of course, depending on the problem and project we're working on) we're looking to achieve as many positives as possible. Useful if we are predicting some possible development of a disease.\n",
        "\n",
        "---\n",
        "\n",
        "This are the three main metrics we can extract when we're working with a classification model. But we can take it an step forward and combine them to get different information.\n",
        "\n",
        "## F1 score\n",
        "The F1 score is a metric between 0 and 1 and it's the harmonic mean between the recall and the precision.\n",
        "> F1 = 2 * (R * P / R + P)\n",
        "\n",
        "When looking at the F1 score we can see that if we're working with an umbalanced dataset, the F1 value will tend to 0 (either because the recall or the precision is close to 0). With this we can clearly see if the accuracy of the model is representative or not -> not in this case.\n",
        "\n",
        "## Curve ROC and AUC\n",
        "This is a very useful classification metric when we're facing problem like this one. The ROC (Receiver operating characteristic) curve is the graphic representation of amount of true (or correct) classifications that a binary classification model will do depending on the sampling. The AUC is the Area Under the Curve. \n",
        "\n",
        "We can extract this curve from the indirect relation between the recall and the precision. If we want to increase the precision, we will decrease the recall and the opposite. This variation depends on what we really want to achieve with the model we're developing: we want it to predict as many true positives as possible or we want to have as many correct predictions as possible?\n",
        "> Therefore, we can make a graph that would look something like this:\n",
        "![picture](https://www.statology.org/wp-content/uploads/2021/08/read_roc2.png)\n",
        "\n",
        "So, deppending on the amount of area that is under this curve, the better the model will be. We can find a method for calculating this in the sklearn library.\n",
        "\n",
        "---\n",
        "\n",
        "After this super fast class about classification metrics we can finally conclude that working with this amount of unbalanced data is neither suitable nor reliable for this case.\n",
        "\n",
        "What we can do now is split our data (or segment it) to repeat the model and look at some metrics again."
      ],
      "metadata": {
        "id": "oQJvdmaZpJrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_df_class0 = df[df.Class == 0].sample(n = 150)\n",
        "reduced_df_class1 = df[df.Class == 1].sample(n = 50)\n",
        "reduced_df = pd.concat([reduced_df_class0, reduced_df_class1])\n",
        "\n",
        "print(reduced_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qIyuXRtywdk",
        "outputId": "9cbefae9-7365-4335-c1a0-de58041cba00"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Time        V1        V2         V3        V4        V5        V6  \\\n",
            "269221  163594.0  1.920637 -1.251337  -0.661176 -0.530568 -1.127583 -0.364154   \n",
            "146417   87690.0 -0.722795  0.993829   1.387846 -0.332280 -0.310226 -0.306936   \n",
            "125533   77706.0  0.628874 -1.013755  -1.384760  0.653579  1.676106  3.934178   \n",
            "157320  109835.0  2.083117  0.123442  -1.337087  0.350009  0.413914 -0.718075   \n",
            "55214    46837.0 -0.681522  0.453120   1.760494  0.926386 -0.967963  1.097663   \n",
            "...          ...       ...       ...        ...       ...       ...       ...   \n",
            "42590    41164.0 -5.932778  4.571743  -9.427247  6.577056 -6.115218 -3.661798   \n",
            "150662   93853.0 -5.839192  7.151532 -12.816760  7.031115 -9.651272 -2.938427   \n",
            "203700  134928.0  1.204934  3.238070  -6.010324  5.720847  1.548400 -2.321064   \n",
            "222133  142840.0 -3.613850 -0.922136  -4.749887  3.373001 -0.545207 -1.171301   \n",
            "93424    64412.0 -1.348042  2.522821  -0.782432  4.083047 -0.662280 -0.598776   \n",
            "\n",
            "               V7        V8        V9  ...       V21       V22       V23  \\\n",
            "269221  -0.807625 -0.009894  0.348820  ... -0.558020 -1.336086  0.438233   \n",
            "146417   0.050198  0.501486  0.003435  ... -0.057655 -0.246898  0.034473   \n",
            "125533  -0.455995  0.938464  0.667406  ...  0.026428 -0.450422 -0.433979   \n",
            "157320   0.102216 -0.381714  1.938685  ...  0.121058  0.784942  0.011420   \n",
            "55214    0.953339  0.224474  0.066964  ...  0.054622  0.441150 -0.054443   \n",
            "...           ...       ...       ...  ...       ...       ...       ...   \n",
            "42590  -10.894079  3.709210 -5.859524  ...  2.014272 -0.167417  0.049968   \n",
            "150662 -11.543207  4.843627 -3.494276  ...  2.462056  1.054865  0.530481   \n",
            "203700  -0.781880  0.076619 -2.976249  ...  0.098341 -0.845866 -0.031228   \n",
            "222133  -4.172315  1.517016 -1.775833  ...  0.786787  0.893065  1.034907   \n",
            "93424   -1.943552 -0.329579 -1.853274  ...  1.079871 -0.352026 -0.218358   \n",
            "\n",
            "             V24       V25       V26       V27       V28  Amount  Class  \n",
            "269221  0.631922 -0.671276 -0.366921 -0.001495 -0.008996  115.00      0  \n",
            "146417  1.114513 -0.328585 -0.587556  0.033372  0.092271    2.49      0  \n",
            "125533  0.949967  0.723647 -0.293073  0.016637  0.097609  312.02      0  \n",
            "157320  0.584434  0.350827 -0.483705 -0.015618 -0.053425    1.00      0  \n",
            "55214   0.253586  0.134866 -0.337310  0.037474 -0.030678  199.00      0  \n",
            "...          ...       ...       ...       ...       ...     ...    ...  \n",
            "42590   0.384430 -0.077884  0.565493  1.792012  0.371007    5.30      1  \n",
            "150662  0.472670 -0.275998  0.282435  0.104886  0.254417  316.06      1  \n",
            "203700  0.421146  0.388361  0.056035  0.491828  0.340847    0.00      1  \n",
            "222133  0.097671 -1.345551 -0.788329  1.055442  0.099971  144.80      1  \n",
            "93424   0.125866 -0.074180  0.179116  0.612580  0.234206    1.00      1  \n",
            "\n",
            "[200 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice, we have a proportion of 3/1, a much greater percentage than in the initial case. We can now re-do the spliting and training of the decission tree model."
      ],
      "metadata": {
        "id": "EX8Q98s-2IOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = reduced_df.drop(labels = ['Class'], axis = 1)\n",
        "y = reduced_df['Class']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 7)"
      ],
      "metadata": {
        "id": "5yfJ2a2H2VpI"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_decision_tree = DecisionTreeClassifier()\n",
        "reduced_decision_tree.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldpr5aC63Ys5",
        "outputId": "8b87c531-a74e-4b0b-d3d4-52a09492e6b4"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = reduced_decision_tree.predict(x_test)\n",
        "print(classification_report(y_test, y_predict))\n",
        "print(roc_auc_score(y_test, y_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N61ijTjk3--m",
        "outputId": "a6397abf-ce2e-4e89-9772-e5dcb68a5946"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97        29\n",
            "           1       0.91      0.91      0.91        11\n",
            "\n",
            "    accuracy                           0.95        40\n",
            "   macro avg       0.94      0.94      0.94        40\n",
            "weighted avg       0.95      0.95      0.95        40\n",
            "\n",
            "0.9373040752351097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now this are some useful conclusions. As we can see, the F1-score of both class 1 and class 0 is more realistic than before. We also have a AUC of 0.93 which is pretty good. \n",
        "\n",
        "We can assume that this model will work better than the one with the unbalanced data. My final touch would be to repeat the random sampling from the bigger dataset to see if the decision tree algorithm is good enough for our purpose or we would need to look for some other classification method. :)"
      ],
      "metadata": {
        "id": "KrBROLkY4c1Y"
      }
    }
  ]
}